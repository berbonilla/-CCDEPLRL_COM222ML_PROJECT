{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64447c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate .conda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5862e39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install numpy pandas matplotlib scikit-learn\n",
    "#!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba7b9d8",
   "metadata": {},
   "source": [
    "# Cell 1: Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0aaf48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f41331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771a7119",
   "metadata": {},
   "source": [
    "# Cell 2: Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b77078e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label Stats After Cleaning:\n",
      "count    229981.000000\n",
      "mean          0.388263\n",
      "std           0.487897\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           1.000000\n",
      "max           1.000000\n",
      "Name: label, dtype: float64\n",
      "NaNs: 0\n",
      "Infs: 0\n",
      "✅ Saved vocab to vocab.pkl\n",
      "Vocab size: 347572\n",
      "Max token id: 347571\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('Training/MultiLanguageTrainDataset.csv')\n",
    "assert 'text' in df.columns and 'label' in df.columns, \"Dataset must have 'text' and 'label' columns.\"\n",
    "\n",
    "# Clean labels: remove NaN or Inf values\n",
    "df = df.dropna(subset=['label'])\n",
    "df = df[np.isfinite(df['label'])]\n",
    "\n",
    "# Convert labels to float32\n",
    "df['label'] = df['label'].astype('float32')\n",
    "\n",
    "# Print label stats\n",
    "print(\"Label Stats After Cleaning:\")\n",
    "print(df['label'].describe())\n",
    "print(f\"NaNs: {df['label'].isna().sum()}\")\n",
    "print(f\"Infs: {(df['label'] == np.inf).sum()}\")\n",
    "\n",
    "# Simple tokenizer\n",
    "def tokenize(text):\n",
    "    text = text.lower()  # Make all text lowercase\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)  # Remove non-alphanumeric characters\n",
    "    return text.split()\n",
    "\n",
    "# Data augmentation placeholder (you may enhance this in the future)\n",
    "def synonym_replacement(tokens, prob=0.1):\n",
    "    return [token if random.random() > prob else \"<UNK>\" for token in tokens]  # Replace with <UNK> with some probability\n",
    "\n",
    "tokenized_texts = [tokenize(text) for text in df['text']]  # Tokenize each text\n",
    "augmented_texts = [synonym_replacement(tokens) for tokens in tokenized_texts]  # Augment the data\n",
    "\n",
    "tokenized_texts += augmented_texts  # Add augmented texts to the tokenized texts\n",
    "labels = df['label'].tolist()  # Original labels\n",
    "labels += labels  # Duplicate labels to match the augmented texts\n",
    "\n",
    "# Enforce labels to be valid floats\n",
    "labels = [0.0 if (np.isnan(lbl) or np.isinf(lbl)) else lbl for lbl in labels]  # Clean labels\n",
    "\n",
    "# Build vocab\n",
    "all_tokens = [token for sublist in tokenized_texts for token in sublist]  # Flatten tokenized texts\n",
    "vocab = {word: idx+1 for idx, (word, _) in enumerate(Counter(all_tokens).most_common())}  # Create vocabulary\n",
    "vocab[\"<PAD>\"] = 0  # Add a padding token\n",
    "\n",
    "import pickle\n",
    "\n",
    "# Save vocab to a file for later use in inference\n",
    "with open(\"vocab.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vocab, f)\n",
    "\n",
    "print(\"✅ Saved vocab to vocab.pkl\")\n",
    "\n",
    "# Find max token id\n",
    "max_token_id = max([\n",
    "    max([vocab.get(token, vocab[\"<PAD>\"]) for token in tokens]) if tokens else vocab[\"<PAD>\"]\n",
    "    for tokens in tokenized_texts\n",
    "])\n",
    "print(f\"Vocab size: {len(vocab)}\")\n",
    "print(f\"Max token id: {max_token_id}\")\n",
    "\n",
    "# Encode texts\n",
    "def encode(tokens, vocab, max_len):\n",
    "    tokens = tokens[:max_len]  # Limit token length\n",
    "    ids = [vocab.get(token, vocab[\"<PAD>\"]) for token in tokens]  # Convert tokens to their respective ids\n",
    "    ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))  # Pad the sequence to the max length\n",
    "    return ids\n",
    "\n",
    "max_len = 100  # Max sequence length\n",
    "encoded_texts = [encode(tokens, vocab, max_len) for tokens in tokenized_texts]  # Encode all texts\n",
    "\n",
    "# Train-test split (80-20 split)\n",
    "X_train, X_val, y_train, y_val = train_test_split(encoded_texts, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Custom dataset class for DataLoader\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels):\n",
    "        self.texts = torch.tensor(texts, dtype=torch.long)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Ensure labels are valid\n",
    "        if torch.isnan(self.labels[idx]) or torch.isinf(self.labels[idx]):\n",
    "            print(f\"Invalid label at index {idx}: {self.labels[idx]}\")\n",
    "            return None\n",
    "        return self.texts[idx], self.labels[idx]\n",
    "\n",
    "# Custom collate function to handle empty batches\n",
    "def custom_collate(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if len(batch) == 0:\n",
    "        return None\n",
    "    return torch.utils.data.dataloader.default_collate(batch)\n",
    "\n",
    "# Create DataLoader for training and validation sets\n",
    "train_dataset = TextDataset(X_train, y_train)\n",
    "val_dataset = TextDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    collate_fn=custom_collate,\n",
    "    num_workers=0,  # Use 0 workers initially for debugging\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=256,\n",
    "    shuffle=False,\n",
    "    collate_fn=custom_collate,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f52811",
   "metadata": {},
   "source": [
    "# Cell 3: Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "327a7793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate: 0.000500\n"
     ]
    }
   ],
   "source": [
    "# Number of input features (now set to embedding dimension)\n",
    "input_dim = 1  # This will be replaced by embedding dimension in the actual model\n",
    "embedding_dim = 300  # Set embedding dimension to 300 (a standard value)\n",
    "vocab_size = len(vocab)  # Vocabulary size from previous cell\n",
    "num_classes = 1  # Binary classification\n",
    "dropout_rate = 0.8  # Adjusted dropout rate for better learning\n",
    "\n",
    "# Define the SelfAttention class as before\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_weights = torch.softmax(self.attention(x), dim=1)\n",
    "        weighted = x * attn_weights\n",
    "        return weighted.sum(dim=1)\n",
    "\n",
    "# Modify the TextCNN model to include an embedding layer\n",
    "class TextCNN(nn.Module):\n",
    "    def __init__(self, vocab_size, input_dim, num_classes, embedding_dim=300, dropout_rate=0.8):\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        # Embedding layer added to convert word indices to dense vectors\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim, 200, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1)\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim, 200, kernel_size=4, padding=2),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1)\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(embedding_dim, 200, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm1d(200),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool1d(1)\n",
    "        )\n",
    "\n",
    "        # Self-Attention Layer\n",
    "        self.attention = SelfAttention(600)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "        # Final fully connected layer for classification\n",
    "        self.fc = nn.Linear(600, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Ensure input x is a LongTensor for the embedding layer\n",
    "        x = x.long()  # Convert to LongTensor (required by Embedding Layer)\n",
    "\n",
    "        # Apply embedding layer to convert word indices into dense vectors\n",
    "        x = self.embedding(x)  # Shape [batch_size, seq_len, embedding_dim]\n",
    "        x = x.permute(0, 2, 1)  # Change shape to [batch_size, embedding_dim, seq_len] for Conv1d\n",
    "\n",
    "        # Apply convolution layers\n",
    "        x1 = self.conv1(x).squeeze(2)\n",
    "        x2 = self.conv2(x).squeeze(2)\n",
    "        x3 = self.conv3(x).squeeze(2)\n",
    "\n",
    "        # Concatenate convolution outputs\n",
    "        x = torch.cat((x1, x2, x3), dim=1)  # Shape [batch_size, 600]\n",
    "\n",
    "        # Apply self-attention\n",
    "        x = self.attention(x.unsqueeze(1))  # Shape [batch_size, 600]\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        x = self.fc(x)  # Final output layer\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = TextCNN(vocab_size, input_dim, num_classes, embedding_dim=embedding_dim, dropout_rate=dropout_rate).to(device)\n",
    "\n",
    "# Define the optimizer, loss function, and scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.005, weight_decay=1e-5)  # Using AdamW for better regularization\n",
    "criterion = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy loss\n",
    "scheduler = torch.optim.lr_scheduler.CyclicLR(\n",
    "    optimizer, base_lr=0.0005, max_lr=0.01, mode=\"triangular\", cycle_momentum=False\n",
    ")\n",
    "\n",
    "print(f\"Learning rate: {optimizer.param_groups[0]['lr']:.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810661ab",
   "metadata": {},
   "source": [
    "# Cell 4: Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe54eee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Train Loss: 0.6675 | Train Acc: 63.47% | Train F1: 0.39 | Train Precision: 0.55 | Train Recall: 0.30\n",
      "Val Loss: 0.5860 | Val Acc: 69.93% | Val F1: 0.49 | Val Precision: 0.73 | Val Recall: 0.37\n",
      "Epoch 2/20 - Train Loss: 0.5627 | Train Acc: 72.89% | Train F1: 0.59 | Train Precision: 0.71 | Train Recall: 0.51\n",
      "Val Loss: 0.5136 | Val Acc: 77.16% | Val F1: 0.65 | Val Precision: 0.82 | Val Recall: 0.54\n",
      "Epoch 3/20 - Train Loss: 0.4917 | Train Acc: 79.48% | Train F1: 0.70 | Train Precision: 0.80 | Train Recall: 0.62\n",
      "Val Loss: 0.4720 | Val Acc: 81.05% | Val F1: 0.73 | Val Precision: 0.82 | Val Recall: 0.65\n",
      "Epoch 4/20 - Train Loss: 0.4397 | Train Acc: 83.83% | Train F1: 0.77 | Train Precision: 0.86 | Train Recall: 0.69\n",
      "Val Loss: 0.4435 | Val Acc: 83.27% | Val F1: 0.76 | Val Precision: 0.87 | Val Recall: 0.68\n",
      "Epoch 5/20 - Train Loss: 0.4013 | Train Acc: 86.78% | Train F1: 0.81 | Train Precision: 0.90 | Train Recall: 0.74\n",
      "Val Loss: 0.4244 | Val Acc: 84.90% | Val F1: 0.79 | Val Precision: 0.87 | Val Recall: 0.72\n",
      "Epoch 6/20 - Train Loss: 0.3739 | Train Acc: 88.80% | Train F1: 0.84 | Train Precision: 0.93 | Train Recall: 0.77\n",
      "Val Loss: 0.4098 | Val Acc: 85.96% | Val F1: 0.80 | Val Precision: 0.89 | Val Recall: 0.73\n",
      "Epoch 7/20 - Train Loss: 0.3547 | Train Acc: 90.14% | Train F1: 0.86 | Train Precision: 0.95 | Train Recall: 0.79\n",
      "Val Loss: 0.3985 | Val Acc: 86.88% | Val F1: 0.82 | Val Precision: 0.90 | Val Recall: 0.75\n",
      "Epoch 8/20 - Train Loss: 0.3411 | Train Acc: 91.02% | Train F1: 0.87 | Train Precision: 0.96 | Train Recall: 0.80\n",
      "Val Loss: 0.3904 | Val Acc: 87.42% | Val F1: 0.82 | Val Precision: 0.91 | Val Recall: 0.75\n",
      "Epoch 9/20 - Train Loss: 0.3311 | Train Acc: 91.64% | Train F1: 0.88 | Train Precision: 0.96 | Train Recall: 0.81\n",
      "Val Loss: 0.3850 | Val Acc: 88.01% | Val F1: 0.83 | Val Precision: 0.91 | Val Recall: 0.77\n",
      "Epoch 10/20 - Train Loss: 0.3239 | Train Acc: 92.08% | Train F1: 0.89 | Train Precision: 0.97 | Train Recall: 0.82\n",
      "Val Loss: 0.3785 | Val Acc: 88.33% | Val F1: 0.84 | Val Precision: 0.92 | Val Recall: 0.77\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 45\u001b[0m\n\u001b[0;32m     42\u001b[0m all_preds, all_labels \u001b[38;5;241m=\u001b[39m [], []\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# Training loop\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     47\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\INAnokananaman\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_data()\n\u001b[0;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[0;32m    739\u001b[0m ):\n",
      "File \u001b[1;32mc:\\Users\\INAnokananaman\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:789\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    787\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    788\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 789\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    790\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    791\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\INAnokananaman\\anaconda3\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[5], line 83\u001b[0m, in \u001b[0;36mTextDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m     82\u001b[0m     \u001b[38;5;66;03m# Ensure labels are valid\u001b[39;00m\n\u001b[1;32m---> 83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misnan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]):\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid label at index \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Early Stopping\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=7, min_delta=0.0, mode='min'):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.mode = mode\n",
    "\n",
    "    def __call__(self, val_loss, val_acc):\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_loss if self.mode == 'min' else val_acc\n",
    "        elif (self.mode == 'min' and val_loss < self.best_score - self.min_delta) or \\\n",
    "             (self.mode == 'max' and val_acc > self.best_score + self.min_delta):\n",
    "            self.best_score = val_loss if self.mode == 'min' else val_acc\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "# Label Smoothing\n",
    "def smooth_labels(labels, smoothing=0.1):\n",
    "    return labels * (1 - smoothing) + 0.5 * smoothing  # Stronger smoothing\n",
    "\n",
    "# Initialize lists to store loss and accuracy values\n",
    "num_epochs = 20\n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "# Early stopping instance\n",
    "early_stopping = EarlyStopping(patience=7, min_delta=0.0, mode='min')  # Using 'min' for loss, 'max' for accuracy\n",
    "\n",
    "# Start training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    # Training loop\n",
    "    for batch in train_loader:\n",
    "        if batch is None:\n",
    "            continue\n",
    "        texts_batch, labels_batch = batch\n",
    "        texts_batch, labels_batch = texts_batch.to(device).long(), labels_batch.to(device).float()\n",
    "\n",
    "        if torch.isnan(labels_batch).any() or torch.isinf(labels_batch).any():\n",
    "            continue\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(texts_batch).squeeze(1)\n",
    "\n",
    "        # Clamping outputs to avoid outliers\n",
    "        outputs = torch.clamp(outputs, min=-50, max=50)\n",
    "\n",
    "        smoothed_labels = smooth_labels(labels_batch, smoothing=0.1)  # Apply label smoothing\n",
    "\n",
    "        loss = criterion(outputs, smoothed_labels)\n",
    "        if torch.isnan(loss) or torch.isinf(loss):\n",
    "            continue\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        preds = torch.round(torch.sigmoid(outputs))\n",
    "        all_preds.extend(preds.detach().cpu().numpy())\n",
    "        all_labels.extend(labels_batch.detach().cpu().numpy())\n",
    "\n",
    "    # Metrics for training\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    mask = ~np.isnan(all_preds) & ~np.isnan(all_labels)\n",
    "    all_preds = all_preds[mask]\n",
    "    all_labels = all_labels[mask]\n",
    "    \n",
    "    train_acc = accuracy_score(all_labels, all_preds)\n",
    "    train_precision = precision_score(all_labels, all_preds)\n",
    "    train_recall = recall_score(all_labels, all_preds)\n",
    "    train_f1 = f1_score(all_labels, all_preds)\n",
    "    \n",
    "    train_losses.append(epoch_loss / len(train_loader))\n",
    "    train_accuracies.append(train_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_losses[-1]:.4f} | Train Acc: {train_accuracies[-1]*100:.2f}% | Train F1: {train_f1:.2f} | Train Precision: {train_precision:.2f} | Train Recall: {train_recall:.2f}\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            if batch is None:\n",
    "                continue\n",
    "            texts_batch, labels_batch = batch\n",
    "            texts_batch, labels_batch = texts_batch.to(device).long(), labels_batch.to(device).float()\n",
    "\n",
    "            outputs = model(texts_batch).squeeze(1)\n",
    "            outputs = torch.clamp(outputs, min=-50, max=50)\n",
    "\n",
    "            smoothed_labels = smooth_labels(labels_batch, smoothing=0.1)  # Apply label smoothing\n",
    "\n",
    "            loss = criterion(outputs, smoothed_labels)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds = torch.round(torch.sigmoid(outputs))\n",
    "            all_preds.extend(preds.detach().cpu().numpy())\n",
    "            all_labels.extend(labels_batch.detach().cpu().numpy())\n",
    "\n",
    "    # Metrics for validation\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "    mask = ~np.isnan(all_preds) & ~np.isnan(all_labels)\n",
    "    all_preds = all_preds[mask]\n",
    "    all_labels = all_labels[mask]\n",
    "\n",
    "    val_acc = accuracy_score(all_labels, all_preds)\n",
    "    val_precision = precision_score(all_labels, all_preds)\n",
    "    val_recall = recall_score(all_labels, all_preds)\n",
    "    val_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "    val_losses.append(val_loss / len(val_loader))\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Val Loss: {val_losses[-1]:.4f} | Val Acc: {val_accuracies[-1]*100:.2f}% | Val F1: {val_f1:.2f} | Val Precision: {val_precision:.2f} | Val Recall: {val_recall:.2f}\")\n",
    "    \n",
    "    # Scheduler and early stopping\n",
    "    scheduler.step()  # Adjust the learning rate\n",
    "    early_stopping(val_losses[-1], val_acc)  # Trigger early stopping if needed\n",
    "    \n",
    "    if early_stopping.early_stop:\n",
    "        print(\"Early stopping triggered. Stopping training.\")\n",
    "        break\n",
    "\n",
    "# Function to plot the graphs for Loss and Accuracy\n",
    "def plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "    plt.plot(val_losses, label='Val Loss', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(train_accuracies, label='Train Acc', color='blue')\n",
    "    plt.plot(val_accuracies, label='Val Acc', color='red')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy over Epochs')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the plot function at the end of training\n",
    "plot_training_history(train_losses, val_losses, train_accuracies, val_accuracies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1af1799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model after training finishes\n",
    "model_save_path = \"modified_model.pth\"\n",
    "torch.save({\n",
    "    'epoch': epoch+1,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'train_losses': train_losses,\n",
    "    'val_losses': val_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'val_accuracies': val_accuracies\n",
    "}, model_save_path)\n",
    "\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc5043e",
   "metadata": {},
   "source": [
    "# Cell 5: Plotting Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412304ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Loss and Accuracy  \n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracies, label='Train Acc')\n",
    "plt.plot(val_accuracies, label='Val Acc')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0c9e13",
   "metadata": {},
   "source": [
    "# Cell 6: Testing the Model on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22f9e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the testing folder\n",
    "test_folder = 'Testing'\n",
    "\n",
    "# Put the model in eval mode\n",
    "model.eval()\n",
    "\n",
    "# Loop over all CSVs in the Testing folder\n",
    "for filename in os.listdir(test_folder):\n",
    "    if filename.endswith('.csv'):\n",
    "        filepath = os.path.join(test_folder, filename)\n",
    "        print(f\"Processing file: {filename}\")\n",
    "\n",
    "        # Load the CSV\n",
    "        df_test = pd.read_csv(filepath)\n",
    "        if 'text' not in df_test.columns or 'label' not in df_test.columns:\n",
    "            print(f\"Skipping {filename}: missing 'text' or 'label' column.\")\n",
    "            continue\n",
    "\n",
    "        # Preprocess: tokenize and encode\n",
    "        tokenized_texts = [tokenize(text) for text in df_test['text']]\n",
    "        encoded_texts = [encode(tokens, vocab, max_len) for tokens in tokenized_texts]\n",
    "\n",
    "        # Convert to tensor\n",
    "        texts_tensor = torch.tensor(encoded_texts, dtype=torch.long).to(device)\n",
    "\n",
    "        # Convert labels\n",
    "        labels_tensor = torch.tensor(df_test['label'].tolist(), dtype=torch.float32).to(device)\n",
    "\n",
    "        # Predict in batches if needed (optional)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(texts_tensor).squeeze(1)\n",
    "            predictions = torch.round(torch.sigmoid(outputs)).detach().cpu().numpy()\n",
    "            actuals = labels_tensor.cpu().numpy()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        accuracy = accuracy_score(actuals, predictions)\n",
    "        print(f\"Accuracy for {filename}: {accuracy*100:.2f}%\")\n",
    "        print('-' * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076cc314",
   "metadata": {},
   "source": [
    "# Cell 7: Load Model and Predict from User Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86986ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model from saved checkpoint\n",
    "model_load_path = \"best_textcnn_model.pth\"\n",
    "\n",
    "try:\n",
    "    checkpoint = torch.load(model_load_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Model loaded successfully from {model_load_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading the model: {e}\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    return text.split()\n",
    "\n",
    "# Encoding function\n",
    "def encode(tokens, vocab, max_len):\n",
    "    ids = [vocab.get(token, vocab[\"<PAD>\"]) for token in tokens[:max_len]]\n",
    "    ids += [vocab[\"<PAD>\"]] * (max_len - len(ids))\n",
    "    return ids\n",
    "\n",
    "max_len = 100  # Must match training\n",
    "\n",
    "# User input loop\n",
    "while True:\n",
    "    user_input = input(\"\\nEnter text to classify (or type 'exit' to quit): \")\n",
    "    if user_input.strip().lower() == 'exit':\n",
    "        print(\"Exiting.\")\n",
    "        break\n",
    "    \n",
    "    tokens = tokenize(user_input)\n",
    "    encoded_input = encode(tokens, vocab, max_len)\n",
    "    input_tensor = torch.tensor([encoded_input], dtype=torch.long).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor).squeeze(1)\n",
    "        prob = torch.sigmoid(output).item()\n",
    "        prediction = 1 if prob >= 0.5 else 0\n",
    "        print(f\"Predicted Label: {prediction} (Probability: {prob:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866bd32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "\n",
    "# Assuming these lists are populated during training\n",
    "# Initialize these lists before training to store the results\n",
    "epochs = np.arange(1, 21)  # Assuming 20 epochs\n",
    "\n",
    "# These should be updated during training in your loop (examples below)\n",
    "train_loss = []  # List to store training loss at each epoch\n",
    "val_loss = []    # List to store validation loss at each epoch\n",
    "train_accuracy = []  # List to store training accuracy at each epoch\n",
    "val_accuracy = []    # List to store validation accuracy at each epoch\n",
    "train_f1 = []        # List to store training F1 score at each epoch\n",
    "val_f1 = []          # List to store validation F1 score at each epoch\n",
    "\n",
    "# After training, the test accuracy per language would look like this (replace with actual values)\n",
    "languages = ['Chinese', 'English', 'Filipino', 'French', 'German', 'Indonesian', 'Italian', 'Korean', 'Spanish']\n",
    "test_accuracy = [65.44, 78.60, 64.91, 74.66, 57.08, 80.41, 69.63, 44.43, 68.54]  # Example\n",
    "\n",
    "# Model summary\n",
    "model = None  # Replace this with your actual model\n",
    "# To get the summary of your model:\n",
    "# print(summary(model, input_size=(1, max_len)))  # For CNN, this assumes 1 input channel, max_len sequence length\n",
    "\n",
    "# Plotting all graphs\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Plot 1: Loss over Epochs (Fig. 1)\n",
    "axs[0, 0].plot(epochs, train_loss, label='Train Loss')\n",
    "axs[0, 0].plot(epochs, val_loss, label='Validation Loss')\n",
    "axs[0, 0].set_title('Fig. 1: Loss vs Epochs')\n",
    "axs[0, 0].set_xlabel('Epochs')\n",
    "axs[0, 0].set_ylabel('Loss')\n",
    "axs[0, 0].legend()\n",
    "\n",
    "# Plot 2: Accuracy over Epochs\n",
    "axs[0, 1].plot(epochs, train_accuracy, label='Train Accuracy')\n",
    "axs[0, 1].plot(epochs, val_accuracy, label='Validation Accuracy')\n",
    "axs[0, 1].set_title('Accuracy over Epochs')\n",
    "axs[0, 1].set_xlabel('Epochs')\n",
    "axs[0, 1].set_ylabel('Accuracy (%)')\n",
    "axs[0, 1].legend()\n",
    "\n",
    "# Plot 3: F1-Score over Epochs\n",
    "axs[1, 0].plot(epochs, train_f1, label='Train F1-Score')\n",
    "axs[1, 0].plot(epochs, val_f1, label='Validation F1-Score')\n",
    "axs[1, 0].set_title('F1-Score over Epochs')\n",
    "axs[1, 0].set_xlabel('Epochs')\n",
    "axs[1, 0].set_ylabel('F1-Score')\n",
    "axs[1, 0].legend()\n",
    "\n",
    "# Plot 4: Test Accuracy per Language (Bar chart)\n",
    "axs[1, 1].bar(languages, test_accuracy, color='skyblue')\n",
    "axs[1, 1].set_title('Test Accuracy per Language')\n",
    "axs[1, 1].set_xlabel('Languages')\n",
    "axs[1, 1].set_ylabel('Accuracy (%)')\n",
    "axs[1, 1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 1. Model Summary (This assumes you're using a CNN model)\n",
    "print(\"Model Summary:\")\n",
    "summary(model, input_size=(1, 100))  # Assuming max_len=100 for sequence length, 1 input channel\n",
    "\n",
    "# 2. Summary Table of Metrics (Final Epoch)\n",
    "metrics_data = {\n",
    "    'Metric': ['Train Loss', 'Validation Loss', 'Train Accuracy', 'Validation Accuracy', 'Train F1-Score', 'Validation F1-Score'],\n",
    "    'Value': [train_loss[-1], val_loss[-1], train_accuracy[-1], val_accuracy[-1], train_f1[-1], val_f1[-1]]\n",
    "}\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"\\nFinal Epoch Metrics:\")\n",
    "print(metrics_df)\n",
    "\n",
    "# 3. Test Accuracy per Language Table\n",
    "test_accuracy_data = {\n",
    "    'Language': languages,\n",
    "    'Test Accuracy': test_accuracy\n",
    "}\n",
    "\n",
    "test_accuracy_df = pd.DataFrame(test_accuracy_data)\n",
    "print(\"\\nTest Accuracy per Language:\")\n",
    "print(test_accuracy_df)\n",
    "\n",
    "# 4. Precision and Recall (if available)\n",
    "# Assuming precision and recall lists are populated during the evaluation process\n",
    "train_precision = []  # Populate during training\n",
    "val_precision = []    # Populate during validation\n",
    "train_recall = []     # Populate during training\n",
    "val_recall = []       # Populate during validation\n",
    "\n",
    "# Create Precision and Recall Table\n",
    "precision_recall_data = {\n",
    "    'Metric': ['Train Precision', 'Validation Precision', 'Train Recall', 'Validation Recall'],\n",
    "    'Value': [train_precision[-1], val_precision[-1], train_recall[-1], val_recall[-1]]\n",
    "}\n",
    "\n",
    "precision_recall_df = pd.DataFrame(precision_recall_data)\n",
    "print(\"\\nPrecision and Recall Metrics:\")\n",
    "print(precision_recall_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
